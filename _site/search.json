{
  "articles": [
    {
      "path": "index.html",
      "title": "Maureen Muthengi",
      "author": [],
      "contents": "\n\nAbout me\nMy name is Maureen Muthengi, and I am a dynamic and accomplished professional with a robust background in data science, public policy, and information technology. I am currently pursuing a Master of Science in Data Science and Analytics from Grand Valley State University, adding to my Bachelor of Science in Information Technology from Jomo Kenyatta University of Agriculture and Technology.\nWith extensive experience at the United Nations High Commissioner for Refugees (UNHCR), I have honed my skills in data extraction, analysis, and visualization using tools such as Microsoft PowerBI, Tableau, R, SQL, and Python. I am adept at project management, stakeholder collaboration, and leadership, with a demonstrated ability to deliver actionable insights and drive decision-making processes. My expertise also extends to IT support, LAN configuration, and troubleshooting.\nDuring my tenure as a Resettlement Associate at UNHCR from 2009 to 2023, I analyzed refugee resettlement data, prepared statistical reports, managed refugee submissions and departure statistics, and designed data collection tools for the Education Department. Additionally, I have been leading the “Donate a Pad Initiative” in Kitui, Kenya since 2012, which aims to support girls in primary and high schools by providing sanitary towels and mentorship.\nMy commitment to continuous learning and professional growth is reflected in my professional certificates, including the Google Data Analytics Professional Certificate and the 10Alytics Data and Strategy certificate. I am also actively involved in various volunteer activities, such as being a data analyst for the Citizen’s Climate Lobby, Vice President of the African Student Council at Grand Valley State University, and a member of the Women in Computing Club and the International Public Policy Association.\nI have presented papers at international conferences, received recognition for my service to UNHCR, and served as a board member and keynote speaker on various occasions. I am passionate about leveraging my skills and experiences to contribute positively to society and drive impactful change through data-driven decision-making.\n\n\n\n",
      "last_modified": "2024-08-01T09:18:29-04:00"
    },
    {
      "path": "project.html",
      "title": "STA 631 Project",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2024-08-01T09:18:29-04:00"
    },
    {
      "path": "STA631.html",
      "title": "STA 631: Statistical Modeling and Regression",
      "author": [],
      "contents": "\nThis course follows a traditional and modern computationally intensive statistical modeling techniques. Basics of probability theory, including conditional probability, Bayes’ Theorem, and univariate probability models. Regression modeling and prediction including simple linear, multiple, logistic, Poisson, nonlinear and nonparametric regression. Methods for model selection and shrinkage. Emphasis is on application and interpretation using statistical software.\nTopics Covered\nSimple Linear Regression\nSimple Linear Regression is a statistical method used to model the relationship between a dependent variable and a single independent variable. The model assumes a linear relationship, where the equation of the line (y = mx + c) represents the best fit for the data points. This method is used to predict the value of the dependent variable based on the independent variable.\nMultiple Linear Regression\nMultiple Linear Regression extends simple linear regression by using two or more independent variables to predict a dependent variable. The model still assumes a linear relationship but includes additional predictors to improve the accuracy of the prediction. The equation takes the form y = b0 + b1x1 + b2x2 + … + bnxn.\nLogistic Regression\nLogistic Regression is used when the dependent variable is categorical, often binary. It models the probability that a given input point belongs to a certain class. Instead of fitting a line, it fits an S-shaped logistic function, which outputs probabilities that can be mapped to binary outcomes.\nMultinomial Regression\nMultinomial Regression is an extension of logistic regression that deals with dependent variables with more than two categories. It models the probabilities of the different possible outcomes of a categorical dependent variable, given a set of independent variables.\nGeneralized Linear Model (GLM)\nGeneralized Linear Models extend linear regression to models with a non-normal distribution of the dependent variable. GLMs consist of three components: a linear predictor, a link function, and a variance function that describes the distribution of the dependent variable. Examples include logistic regression and Poisson regression.\nResampling and Cross-validation\nResampling methods, such as bootstrapping and permutation tests, involve repeatedly drawing samples from the data and refitting the model to understand the variability of the estimator. Cross-validation is a technique for assessing how well a model generalizes to an independent dataset by partitioning the data into training and testing sets multiple times.\nModel Selection and Multiple Testing\nModel selection involves choosing the best model from a set of potential models based on criteria like AIC, BIC, or adjusted R-squared. Multiple testing refers to the statistical analysis process where multiple hypotheses are tested simultaneously. Adjustments like Bonferroni correction are used to control the family-wise error rate.\nTools Used\nR Studio\nRStudio is our go-to integrated development environment (IDE) for R, the programming language we use for statistical computing and graphics in STA 631. It offers a user-friendly interface with a console, syntax-highlighting editor, and essential tools for plotting, history, and workspace management. This setup makes developing our R scripts and projects both efficient and enjoyable.\nGitHub\nGitHub is an essential tool for us in STA 631, facilitating version control and collaborative software development. This web-based platform hosts our Git repositories and provides us with tools for code review, project management, and collaboration. By using GitHub, we can efficiently track changes, manage issues, and contribute to projects, making it an invaluable resource for our class activities and projects.\nText Materials\nAn Introduction to Statistical Learning with R (ISLR)\n“An Introduction to Statistical Learning with R” (ISLR) by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani is a comprehensive guide to statistical learning methods. It covers a range of topics, including linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more, with practical examples using R.\nData Feminism\n“Data Feminism” by Catherine D’Ignazio and Lauren F. Klein explores the intersection of data science and feminism. The book discusses how data science can be used to challenge power structures and promote social justice. It emphasizes the importance of considering context, ethics, and the voices of marginalized groups in data practices.\nTidy Modeling with R\n“Tidy Modeling with R” by Max Kuhn and Julia Silge introduces the tidymodels framework for modeling and machine learning in R. The book covers a range of modeling techniques, from basic to advanced, using a consistent and tidy approach. It emphasizes practical applications, reproducibility, and ease of use.\nR for Data Science (2nd Edition)\n“R for Data Science” by Hadley Wickham and Garrett Grolemund is an essential guide for anyone working with data in R. The second edition covers the tidyverse, a collection of R packages designed for data science. Topics include data import, tidying, transformation, visualization, and modeling, with a focus on practical applications and real-world examples.\nReflections\nThis course was highly interactive, led by Professor Bradford Dykes, who conducted sessions every Monday. We engaged in activities, assignments, and projects that allowed us to apply the knowledge acquired on various models taught in class. I appreciated the use of the “Muddy” platform in Ms Teams, where we could share our challenges, errors, and any issues encountered while working on the activities. This facilitated discussions with classmates, enabling us to find solutions collaboratively. The one-on-one sessions with Professor Dykes were immensely helpful whenever we faced challenges with the activities. Additionally, I valued the requirement to share our assignments, projects, and activities with peers for recommendations before submission, as their feedback provided valuable insights and enhancements to our work.\n\n\n\n",
      "last_modified": "2024-08-01T09:18:30-04:00"
    }
  ],
  "collections": ["Project/Project.json", "STA631 Course/STA631 Course.json"]
}
